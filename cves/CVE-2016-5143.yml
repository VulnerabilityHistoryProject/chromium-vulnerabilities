---
CVE: CVE-2016-5143
CWE: 22
announced: 2016-08-07 15:59:07.830000000 -04:00
description_instructions: |
  You can get an initial description from the CVE entry on cve.mitre.org. These
  descriptions are a fine start, but they can be kind of jargony.

  Rewrite this description in your own words. Make it interesting and easy to
  read to anyone with some programming experience. We can always pull up the NVD
  description later to get more technical.

  Try to still be specific in your description, but remove Chromium-specific
  stuff. Remove references to versions, specific filenames, and other jargon
  that outsiders to Chromium would not understand. Technology like "regular
  expressions" is fine, and security phrases like "invalid write" are fine to
  keep too.
description: |
  There is a potential access control vulnerability in the DevTools subsystem
  of Google Chrome. The subsystem allows for a hostname and other parameters
  to be passed in by the user. The system does not sanitize the parameters
  properly, which creates an opening for an attacker to supply their own
  hostname and parameters by passing in a specially crafted URL.
bounty:
  date: 2016-08-03 14:54:00.000000000 -04:00
  amount: 1000.0
  references:
  - http://chromereleases.googleblog.com/2016/08/stable-channel-update-for-desktop.html
reviews:
- 2179623002
- 2065823004
bugs:
- 619414
repo:
fixes_vcc_instructions: |
  Please put the commit hash in "commit" below (see my example in
  CVE-2011-3092.yml). Fixes and VCCs follow the same format.
fixes:
- :commit: 554517a4587bfb0071bcd3c7eff6645a0b06d72a
  :note: ''
vccs:
- commit: 36b91b446fbc09f334d6c7c8575477330ea9d39a
  note: |
    This commit was specifically to remove any `../` found in the sourceURL,
    meaning they were trying to fix another vulnerability and accidentally
    introduced this one
- commit: e8ecfb59d4f906e0ab40b6046406b8af1366cb10
  note: |
    This was a commit that attempted to validate the remote base passed in,
    but did it in an incomplete way.
- commit: c5eecf67fd8d5e8d24d2d4d9489753d2c8cf6c59
  note: |
    This commit was intended to sanitize the remote front end URL for any
    old front ends. It sanitized the URL, but it did not address any of the holes
    that were found in this vulnerability.
upvotes_instructions: |
  For the first round, ignore this upvotes number.

  For the second round of reviewing, you will be giving a certain amount of
  upvotes to each vulnerability you see. Your peers will tell you how
  interesting they think this vulnerability is, and you'll add that to the
  upvotes score on your branch.
upvotes: 4
unit_tested:
  question: |
    Were automated unit tests involved in this vulnerability?
    Was the original code unit tested, or not unit tested? Did the fix involve
    improving the automated tests?

    For the "code" answer below, look not only at the fix but the surrounding
    code near the fix and determine if and was there were unit tests involved
    for this module.

    For the "fix" answer below, check if the fix for the vulnerability involves
    adding or improving an automated test to ensure this doesn't happen again.
  answer: No
  code: false
  fix: false
discovered:
  question: |
    How was this vulnerability discovered?

    Go to the bug report and read the conversation to find out how this was
    originally found. Answer in longform below in "answer", fill in the date in
    YYYY-MM-DD, and then determine if the vulnerability was found by a Google
    employee (you can tell from their email address). If it's clear that the
    vulenrability was discovered by a contest, fill in the name there.

    The "automated" flag can be true, false, or nil.
    The "google" flag can be true, false, or nil.

    If there is no evidence as to how this vulnerability was found, then you may
    leave this part blank.
  answer: |
    This was found by a Google employee (gmail.com email address), and reproduced by
    a Chromium employee. The original reporter was able to pass in a crafted URL
    that was 'sanitized' to remove the expected hostname, and add their own.
  date: 2016-06-12
  automated: false
  google: true
  contest: # N/A
subsystem:
  question: |
    What subsystems was the mistake in?

    Look at the path of the source code files code that were fixed to get
    directory names. Look at comments in the code. Look at the bug reports how
    the bug report was tagged.
  answer: Based on the description in the CVE and where the files were located
  name: Webkit
interesting_commits:
  question: |
    Are there any interesting commits between your VCC(s) and fix(es)?

    Write a brief (under 100 words) description of why you think this commit was
    interesting in light of the lessons learned from this vulnerability. Any
    emerging themes?
  commits:
  - commit: 3d330b46d9e6ad9479afc323e45dc5bfcb4514d1
    note: (devtools.js) There are many commits addressing linting issues, but not many code changes in between the VCC and the fix. It seems that this file was generally unchanged.
  - commit: ea75e1f92889b869d80be178018bd85705d886a9
    note: (Runtime.js) This commit separates the front end into 2 different applications. This could potentially have introduced issues with URL validation, going from 1 application with 1 url to 2 applications with 2 different urls.
  - commit: 679e5641c8492ae5bb260e45dcaebcc26910fa54
    note: (Runtime.js) This allows embedding the remote front end. This is interesting because it shows a trend of the developer trusting the input of the user. In this case, the url is taken from the runtime query param, and it doesn't seem to be sanitized in any way.
major_events:
  question: |
    Please record any major events you found in the history of this
    vulnerability. Was the code rewritten at some point? Was a nearby subsystem
    changed? Did the team change?

    The event doesn't need to be directly related to this vulnerability, rather,
    we want to capture what the development team was dealing with at the time.
  answer: |
    The most major event is when the application got split into two front end
    applications. This shows some major overhaul of the front end Webkit.
  events:
  - name: Two Application Split
    date: Sep 24, 2014
lessons:
  question: |
    Are there any common lessons we have learned from class that apply to this
    vulnerability? In other words, could this vulnerability serve as an example
    of one of those lessons?

    Leave "applies" blank or put false if you did not see that lesson (you do
    not need to put a reason). Put "true" if you feel the lesson applies and put
    a quick explanation of how it applies.

    Don't feel the need to claim that ALL of these apply, but it's pretty likely
    that one or two of them apply.

    If you think of another lesson we covered in class that applies here, feel
    free to give it a small name and add one in the same format as these.
  defense_in_depth:
    applies:
    note:
  least_privilege:
    applies:
    note:
  frameworks_are_optional:
    applies:
    note:
  native_wrappers:
    applies:
    note:
  distrust_input:
    applies: true
    note: |
      This vulnerability was caused from trusting user input too much. The sanitization assumed
      that the worst the user would do is input a relative path "../", when in reality that's
      not a safe assumption to make.
  security_by_obscurity:
    applies:
    note:
  serial_killer:
    applies:
    note:
  environment_variables:
    applies:
    note:
  secure_by_default:
    applies:
    note:
  yagni:
    applies:
    note:
  complex_inputs:
    applies:
    note:
mistakes:
  question: |
    In your opinion, after all of this research, what mistakes were made that
    led to this vulnerability? Coding mistakes? Design mistakes?
    Maintainability? Requirements? Miscommunications?

    Look at the CWE entry for this vulnerability and examine the mitigations
    they have written there. Are they doing those? Does the fix look proper?

    Use those questions to inspire your answer. Don't feel obligated to answer
    every one. Write a thoughtful entry here that those ing the software
    engineering industry would find interesting.
  answer: |
    The main coding mistake here was the attempted fix of the original path traversal
    vulnerability. Sanitizing input by removing all "../" was a good first step, but
    when input becomes more complicated, the fix falls apart.

    I believe this vulnerability could have been avoided using unit tests. There are no unit
    tests specifically for the Runtime file, which is a concern. Sending in a complex input
    in a unit test would have shown the developer that their sanitization algorithm
    may not be as robust as intended.
