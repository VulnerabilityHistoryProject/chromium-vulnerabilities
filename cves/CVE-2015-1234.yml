---
CVE: CVE-2015-1234
CWE_instructions: |
  Please go to cwe.mitre.org and find the most specific, appropriate CWE entry
  that describes your vulnerability. (Tip: this may not be a good one to start
  with - spend time understanding this vulnerability before making your choice!)
CWE: 362
curated_instructions: |
  If you are manually editing this file, then you are "curating" it. Set the
  entry below to "true" as soon as you start. This will enable additional
  integrity checks on this file to make sure you fill everything out properly.
  If you are a student, we cannot accept your work as finished unless curated is
  set to true.
curated: true
announced_instructions: |
  Was there a date that this vulnerability was announced to the world? You can
  find this in changelogs, blogs, bug reports, or perhaps the CVE date. A good
  source for this is Chrome's Stable Release Channel
  (https://chromereleases.googleblog.com/).
  Please enter your date in YYYY-MM-DD format.
announced: 2015-04-01
description_instructions: |
  You can get an initial description from the CVE entry on cve.mitre.org. These
  descriptions are a fine start, but they can be kind of jargony.

  Rewrite this description in your own words. Make it interesting and easy to
  read to anyone with some programming experience. We can always pull up the NVD
  description later to get more technical.

  Try to still be specific in your description, but remove Chromium-specific
  stuff. Remove references to versions, specific filenames, and other jargon
  that outsiders to Chromium would not understand. Technology like "regular
  expressions" is fine, and security phrases like "invalid write" are fine to
  keep too.
description: |
  This vulnerability was a consequence of how the GPU and the native client application
  interact with each other. Essentially, they communicate using threads and shared
  memory to send commands and receive return values. The problem was in a specific
  block of code that accessed a specific resource in untrusted shared memory.

  There was a race condition where multiple threads were trying to access and/or
  modify the size of a shared resource, so if the timing between the threads was
  not perfect, it would be possible to access this resource, validate it, and then
  later modify it to cause a buffer overflow, which means that an attacker could
  potentially execute their own piece of code. So while there is a buffer overlow
  issue here, it is mostly the race condition that allows for this vulnerability.
bounty_instructions: |
  If you came across any indications that a bounty was paid out for this
  vulnerability, fill it out here. Or correct it if the information already here
  was wrong. Otherwise, leave it blank.
bounty:
  date: 
  amount: 
  references: []
reviews:
- 1016193003
- 1021803003
- 1034093002
bugs:
- 468936
repo: https://chromium.googlesource.com/chromium/src
fixes_vcc_instructions: |
  Please put the commit hash in "commit" below (see my example in
  CVE-2011-3092.yml). Fixes and VCCs follow the same format.
fixes:
- commit: 181c7400b2bf50ba02ac77149749fb419b4d4797
  note: |
    Main fix was to use a computed value instead of a value in shared memory. This ensures that
    the value being used can be trusted.
vccs:
- commit: 939e7367d5d984efe1f402c7e5135503beaebfae
  note: |
    They were adding a wrapper to support BOOL types. There is a specific line that
    was particularly responsible for the CVE: GLsizei num_values = result->GetNumResults();
upvotes_instructions: |
  For the first round, ignore this upvotes number.

  For the second round of reviewing, you will be giving a certain amount of
  upvotes to each vulnerability you see. Your peers will tell you how
  interesting they think this vulnerability is, and you'll add that to the
  upvotes score on your branch.
upvotes: 5
unit_tested:
  question: |
    Were automated unit tests involved in this vulnerability?
    Was the original code unit tested, or not unit tested? Did the fix involve
    improving the automated tests?

    For the "code" answer below, look not only at the fix but the surrounding
    code near the fix and determine if and was there were unit tests involved
    for this module.

    For the "fix" answer below, check if the fix for the vulnerability involves
    adding or improving an automated test to ensure this doesn't happen again.
  answer: |
    There are unit tests for the code in the file in question, but it seems like
    no tests were modified or added because of the vulnerability.
  code: true
  fix: false
discovered:
  question: |
    How was this vulnerability discovered?

    Go to the bug report and read the conversation to find out how this was
    originally found. Answer in longform below in "answer", fill in the date in
    YYYY-MM-DD, and then determine if the vulnerability was found by a Google
    employee (you can tell from their email address). If it's clear that the
    vulenrability was discovered by a contest, fill in the name there.

    The "automated" flag can be true, false, or nil.
    The "google" flag can be true, false, or nil.

    If there is no evidence as to how this vulnerability was found, then you may
    leave the entries blank except for "answer". Write down where you looked in "answer".
  answer: |
    Seems like a hacker with the alias of lokihardt found this vulnerability during a contest
    (evidence here https://securitytracker.com/id/1032012).
  date: 2015-03-19
  automated: false
  google: false
  contest: Pwn2Own
subsystem:
  question: |
    What subsystems was the mistake in?

    Look at the path of the source code files code that were fixed to get
    directory names. Look at comments in the code. Look at the bug reports how
    the bug report was tagged. Examples: "clipboard", "gpu", "ssl", "speech", "renderer"
  answer: Based on the "Components" label in the bug report.
  name: GPU
interesting_commits:
  question: |
    Are there any interesting commits between your VCC(s) and fix(es)?

    Write a brief (under 100 words) description of why you think this commit was
    interesting in light of the lessons learned from this vulnerability. Any
    emerging themes?

    If there are no interesting commits, demonstrate that you completed this section by explaining what happened between the VCCs and the fix.
  answer: |
    A lot of the work leading up to the fix was related to buffers or to texture displays. It seems like the
    vulnerability was difficult to find and was fixed immediately after it was reported.
  commits:
  - commit: d049874acef2be3c17612d4a06b480f3a45ea6e9
    note: |
      They were experiencing multiple minor bugs, so they preemptively added logging functionality
      to multiple files, including the file that introduced the vulnerability. While this is a
      safe and effective way to diagnose future issues, it seems like they were logging a bit too
      much, just by looking at the amount of log commands in each file within this commit.
  - commit: 0140c18b7e341dd2c4e81f9323e830c69574cda1
    note: |
      They seemed to be doing a lot of work with GPU buffers, which is heavily related to the
      vulnerability. Even still, the vulnerability was only found years after the VCC was introduced.
      This leads me to believe that, even though the vulnerability was critical, it was mostly
      hidden behind a race condition that was not really being tested. While this vulnerability
      was easy to reproduce, it was very difficult to find.
major_events:
  question: |
    Please record any major events you found in the history of this
    vulnerability. Was the code rewritten at some point? Was a nearby subsystem
    changed? Did the team change?

    The event doesn't need to be directly related to this vulnerability, rather,
    we want to capture what the development team was dealing with at the time.
  answer: |
    No specific event was found, but it seems like the file in question was being worked on by
    multiple people across some big companies (e.g. Intel, Samsung, Nvidia). Too many developers
    could have lead to multiple issues. For example, a lack of good communication between developers
    can increase the chances of introducing bugs or vulnerabilities, especially when the developers
    are spread across multiple companies.
  events:
  - name: 
    date: 
  - name: 
    date: 
lessons:
  question: |
    Are there any common lessons we have learned from class that apply to this
    vulnerability? In other words, could this vulnerability serve as an example
    of one of those lessons?

    Leave "applies" blank or put false if you did not see that lesson (you do
    not need to put a reason). Put "true" if you feel the lesson applies and put
    a quick explanation of how it applies.

    Don't feel the need to claim that ALL of these apply, but it's pretty likely
    that one or two of them apply.

    If you think of another lesson we covered in class that applies here, feel
    free to give it a small name and add one in the same format as these.
  defense_in_depth:
    applies: 
    note: 
  least_privilege:
    applies: 
    note: 
  frameworks_are_optional:
    applies: 
    note: 
  native_wrappers:
    applies: 
    note: 
  distrust_input:
    applies: true
    note: |
      I feel that this applies in terms of input between processes. The vulnerability was
      largely possible due to shared memory between processes, and the fix was mostly about
      validating limits and data that was transferred between processes.
  security_by_obscurity:
    applies: 
    note: 
  serial_killer:
    applies: 
    note: 
  environment_variables:
    applies: 
    note: 
  secure_by_default:
    applies: 
    note: 
  yagni:
    applies: 
    note: 
  complex_inputs:
    applies: 
    note:
  DoS_in_many_forms:
    applies: true
    note: |
      This lesson applies because a DoS was extremely likely to occur if the vulnerability was exploited.
      This would have happened through a race condition and overflow weakness, which is not the common way
      to produce a DoS attack.
mistakes:
  question: |
    In your opinion, after all of this research, what mistakes were made that
    led to this vulnerability? Coding mistakes? Design mistakes?
    Maintainability? Requirements? Miscommunications?

    Look at the CWE entry for this vulnerability and examine the mitigations
    they have written there. Are they doing those? Does the fix look proper?

    Use those questions to inspire your answer. Don't feel obligated to answer
    every one. Write a thoughtful entry here that those in the software
    engineering industry would find interesting.
  answer: |
    I feel that this vulnerability was more of a design mistake, followed by maintainability
    issues. There is quite a bit of reliance on untrusted shared memory here because of the
    way that the different processes communicate with each other, and this is part of the
    architecture for this application, which means it is very difficult to change. This
    reliance, combined with the complexity that comes naturally with concurrent processes,
    exposes the application to a myriad of issues that may be very difficult to identify.

    Moreover, there were multiple code design flaws that overlooked the atomicity of certain
    operations in the code. In other words, by looking at the VCC and comparing it with the
    fix, it seemed like the original code was using the "easiest" path to retrieve data in
    shared memory, even when these operations were not atomic and introduced the possibility
    of race conditions. And since this code had been present for years before the fix, it
    propagated to other parts of the system. In fact, there was even some discussion in the
    bug report about volatile memory in other parts of the code that was not identified as such,
    so this vulnerability exposed other maintainability issues that required more time and effort
    from the developers.

    Finally, the fix seems to implement some proper ways to deal with the race condition issue,
    specifically the use of volatile type modifiers in the code to indicate the use of untrusted
    shared memory. In addition, the fix also introduces a better use of atomic operations by avoiding
    having to calculate, access, or write to shared memory more times than is necessary.
